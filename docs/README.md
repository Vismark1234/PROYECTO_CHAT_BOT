# Chatbot BAERA - UMSA

Sistema de chatbot inteligente para informaciÃ³n sobre la Beca Comedor BAERA de la Universidad Mayor de San AndrÃ©s (UMSA), construido con LangChain y conectado a datos reales en formato CSV.

## ğŸš€ CaracterÃ­sticas

- âœ… Backend Python con Flask y LangChain
- âœ… IntegraciÃ³n con OpenAI GPT-3.5-turbo
- âœ… Datos cargados desde archivos CSV
- âœ… Vector store con ChromaDB para bÃºsqueda semÃ¡ntica
- âœ… Memoria conversacional
- âœ… Frontend moderno con interfaz de chat
- âœ… Iframe integrado con portal BECATS

## ğŸ“‹ Requisitos Previos

- Python 3.8 o superior
- Node.js (opcional, solo para desarrollo frontend)
- API Key de OpenAI

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar o descargar el proyecto

```bash
cd "C:\Users\Vismark Choque\Documents\PROYECTO CHAT BOT"
```

### 2. Crear entorno virtual de Python

```bash
python -m venv venv
```

### 3. Activar entorno virtual

**Windows:**
```bash
.\venv\Scripts\activate
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 4. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 5. Configurar variables de entorno

Copia el archivo `.env.example` a `.env`:

```bash
copy .env.example .env
```

Edita el archivo `.env` y agrega tu API Key de OpenAI:

```
OPENAI_API_KEY=tu_api_key_aqui
```

**Â¿DÃ³nde obtener la API Key?**
1. Ve a https://platform.openai.com/api-keys
2. Inicia sesiÃ³n o crea una cuenta
3. Crea una nueva API key
4. CÃ³piala y pÃ©gala en el archivo `.env`

## ğŸ¯ Uso

### Iniciar el backend

```bash
python app.py
```

El servidor se iniciarÃ¡ en `http://localhost:5000`

### Abrir el frontend

Simplemente abre el archivo `index.html` en tu navegador:

```bash
start index.html
```

O usa un servidor local (recomendado):

```bash
# Con Python
python -m http.server 8000

# Luego abre http://localhost:8000 en tu navegador
```

## ğŸ“ Estructura del Proyecto

```
PROYECTO CHAT BOT/
â”œâ”€â”€ app.py                      # Backend Flask con LangChain
â”œâ”€â”€ index.html                  # Frontend HTML
â”œâ”€â”€ script.js                   # LÃ³gica del chatbot frontend
â”œâ”€â”€ styles.css                  # Estilos CSS
â”œâ”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ .env                        # Variables de entorno (no incluido en git)
â”œâ”€â”€ .env.example               # Plantilla de variables de entorno
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ becas.csv                   # Datos de becas
â”œâ”€â”€ requisitos.csv              # Requisitos
â”œâ”€â”€ documentos_requeridos.csv   # Documentos necesarios
â”œâ”€â”€ proceso_postulacion.csv     # Proceso de postulaciÃ³n
â”œâ”€â”€ servicios.csv               # Servicios ofrecidos
â”œâ”€â”€ horarios.csv                # Horarios de atenciÃ³n
â”œâ”€â”€ contactos.csv               # InformaciÃ³n de contacto
â””â”€â”€ create_database.sql         # Script SQL para Supabase (opcional)
```

## ğŸ”§ API Endpoints

### `POST /api/chat`
Enviar un mensaje al chatbot

**Request:**
```json
{
  "message": "Â¿CuÃ¡les son los requisitos para la beca?",
  "session_id": "session_123"
}
```

**Response:**
```json
{
  "success": true,
  "message": "Los requisitos para la beca BAERA son...",
  "sources": [...]
}
```

### `GET /api/health`
Verificar estado del servidor

**Response:**
```json
{
  "status": "ok",
  "chatbot_ready": true
}
```

### `POST /api/reset`
Reiniciar conversaciÃ³n

**Request:**
```json
{
  "session_id": "session_123"
}
```

### `GET /api/data/summary`
Obtener resumen de datos cargados

## ğŸ“Š Datos

Los datos del chatbot se cargan desde archivos CSV que contienen informaciÃ³n sobre:

- **Becas**: InformaciÃ³n general de la beca BAERA
- **Requisitos**: Condiciones para aplicar
- **Documentos**: DocumentaciÃ³n necesaria
- **Proceso**: Pasos de postulaciÃ³n
- **Servicios**: Desayuno, almuerzo, cena
- **Horarios**: Horarios de atenciÃ³n
- **Contactos**: InformaciÃ³n de contacto

## ğŸ¤– CÃ³mo Funciona

1. **Carga de Datos**: Al iniciar, el backend carga todos los archivos CSV
2. **Embeddings**: Convierte los datos en vectores usando OpenAI Embeddings
3. **Vector Store**: Almacena los vectores en ChromaDB para bÃºsqueda rÃ¡pida
4. **ConversaciÃ³n**: Cuando el usuario envÃ­a un mensaje:
   - Se buscan los documentos mÃ¡s relevantes
   - Se envÃ­a el contexto + pregunta a GPT-3.5
   - GPT genera una respuesta basada en los datos reales
   - Se mantiene el historial de conversaciÃ³n

## ğŸ¨ PersonalizaciÃ³n

### Cambiar el modelo de IA

En `app.py`, lÃ­nea ~120:

```python
llm = ChatOpenAI(
    model_name="gpt-4",  # Cambiar a gpt-4 para mejor calidad
    temperature=0.7,
    openai_api_key=OPENAI_API_KEY
)
```

### Modificar el nÃºmero de documentos recuperados

En `app.py`, lÃ­nea ~130:

```python
retriever=vectorstore.as_retriever(search_kwargs={"k": 5})  # Cambiar k
```

### Cambiar la URL del backend

En `script.js`, lÃ­nea 11:

```javascript
const API_URL = 'http://tu-servidor.com/api/chat';
```

## ğŸ› SoluciÃ³n de Problemas

### El chatbot no responde

1. Verifica que el backend estÃ© ejecutÃ¡ndose
2. Revisa la consola del navegador (F12) para errores
3. Verifica que la API Key de OpenAI sea vÃ¡lida

### Error "OPENAI_API_KEY no encontrada"

AsegÃºrate de haber creado el archivo `.env` y agregado tu API key.

### Error de CORS

Si el frontend y backend estÃ¡n en diferentes puertos, asegÃºrate de que CORS estÃ© habilitado en `app.py` (ya estÃ¡ configurado).

### ChromaDB no se crea

Verifica que tengas permisos de escritura en la carpeta del proyecto.

## ğŸ“ Notas

- El chatbot usa GPT-3.5-turbo por defecto (mÃ¡s econÃ³mico)
- Los datos se cargan en memoria al iniciar el servidor
- El vector store se guarda en `./chroma_db`
- Las conversaciones se mantienen en memoria (se pierden al reiniciar)

## ğŸš€ PrÃ³ximos Pasos

- [ ] Implementar persistencia de conversaciones en base de datos
- [ ] Agregar autenticaciÃ³n de usuarios
- [ ] Conectar a Supabase en lugar de CSV
- [ ] Agregar mÃ¡s fuentes de datos
- [ ] Implementar rate limiting
- [ ] Agregar analytics y mÃ©tricas

## ğŸ“„ Licencia

Este proyecto es de uso interno para la UMSA.

## ğŸ‘¥ Contacto

Para soporte o consultas sobre el chatbot, contacta al equipo de desarrollo.
